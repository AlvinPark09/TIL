분류_지도 _KNN_K-Nearest_neighbor

- KNN 알고리즘(K개의 가장 가까운 이웃 중에서 어떤 범주가 가장 비중이 높은가?)
  - 가장 간단한 지도학습 머신러닝 알고리즘
  - 훈련데이터를 저장해 두는 것이 모델을 만드는 과정의 전부임
  - 새로운 데이터가 입력되면 그 새로운 데이터 주변의 가장 가까운 K개의 훈련 데이터를 레이블을 확인한 뒤, 가장 많이 보이는 라벨로 분류하는 방법
- K의 결정
  - KNN에서 K의 결정은 매우 중요한 문제임
  - K가 작으면 이상점 등의 노이즈에 민감하게 반응하는 과적합의 문제
  - K가 크면 자료의 패턴을 잘 파악할 수 없어서 예측 성능이 저하됨
  - 검증용(validation)데이터를 이용하여 주어진 훈련 데이터에 가장 적절한 K를 찾아야함
- 거리의 측정
  - n개의 특성변수를 가지는 자료에서 두 개의 관찰점
  - 유클리디안 거리
    - d(a,b) = sqrt( (a1-b1)^2+(a2-b2)^2+---------+(an-bn)^2 )
  - 맨해튼 거리
    - d(a,b) = abs( (a1-b1)^2+(a2-b2)^2+---------+(an-bn)^2 )
  - 민코우스키 거리
  - 자료에 **스케일에 차이가 있는 경우**, 스케일이 큰 특성변수에 의해 거리가 결정되어 버릴 수 있음. 따라서 각 특성변수 별로 스케일이 유사해 지도록 **표준화 변환(Z score)** 또는 **min-max 변환으로 스케일링**을 해준 뒤 거리를 재는 것이 적절함.