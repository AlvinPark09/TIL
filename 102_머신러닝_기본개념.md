## 머신러닝 기본 개념

- 머신 러닝

  - 컴퓨터 시스템에 명시적으로 프로그래밍 하지 않더라도 데이터를 스스로 학습하여 문제를 해결할 수 있게하는 기술을 의미
  - 사람이 인지하기 어려운 복잡한 규칙과 패턴을 파악하여 의미있는 결과를 얻을 수 있음

- 머신러닝 방법론의 분로

  - 지도학습(supervised learning) -> y가 있는 경우
    - 라벨이 있는 훈련용 데이터에서, 여러 특성 변수를 이용하여 목표변수인 라벨(label)을 예측하도록 모델을 학습함
    - 라벨의 데이터 타입에 따라 라벨이 연속형이면 회귀(regression) 알고리즘, 라벨이 범주형이면 분류(classification) 알고리즘으로 구분함
    - 대표 알고리즘
      - Linear Regression,분류형[k-nearest Neighbors, Logistic Regression, softmax Regression], 분류형, 회귀형 [Decision Tree, SVM, Random Forest, Boosting, Neural Network, Deep Learning]
    - 분류(classification) VS 회귀(regression)
      - 분류는 범주형 데이터를 병이 있는 사람, 건강한 사람 분류의 문제
      - 회귀는 어떤 함수로 정의할 수 있을까? 독립변수 x에따라 변화하는 종속변수 y
  - 비지도학습(Unsupervised learning) ->y value(종속변수)가 없는 경우
    - **라벨이 없는** 훈련용 데이터에서 특징 변수들 간의 관계나 유사성을 기반으로 의미있는 패턴을 추출
    - **자율학습** 이라고도 함
    - 군집화(clustering), 차원축소, 추천시스템 등에 활용됨
    - 대표 알고리즘
      - k-means clustering: x(특성변수들)가 얼마나 비슷한가를 기준으로 없던 레이블을 붙여줌
      - hierarchical clustering: x (특성변수)가 너무 많으면 문제를 일으킬 수 있어 특성변수만 모아서 차원 축소를 하는 것. 가지고 있는 정보를 최대로 반영하면서 소수의 특성변수들만 남기는 방법
      - PCA, t_SNE, Apriori, Auto-Encoders
  - 강화학습(Reinforcement Learning)
    - 행동하는 주체(agent)가 있고 행동을 했을 때의 상태와 보상을 바꿔주는 환경으로 구성됨
    - 주체가 매번 어떠한 행동을 하면 환경에 의해 상태와 보상이 바뀌면서 주체는 보상이 가장 커지는 방향으로 계속 학습해 나가게 됨
    - 대표 알고리즘.
      - SARSA, Q-Learning

- 머신러닝 모델의 분석 절차

  - 모델 기반 지도학습 알고리즘의 일반적인 분석절차

    - 주어진 데이터 전처리 및 탐색
    - 적절한 모델을 선택
    - 주어진 데이터로 모델을 훈련시킴
    - 훈련된 모델을 적용하여 새로운 데이터에 대한 예측을 수행

  - 과대적합(overfitting)의 문제

    - 주어진 자료는 거의 완벽한 예측이 가능하지만, 미래의 새로운 자료에 대한 예측력이 떨어지는 문제
    - 복잡한 알고리즘을 사용하여 데이터를 훈련하는 경우 과대적합 문제를 항상 염두해 두어야 함

  - 모델의 검증 및 평가 개요

    - 모델 평가의 필요성
      - 과대적합을 막고 일반화 오차를 줄이기 위해서는, 새로운 데이터에 얼마나 잘 일반화 될지를 파악해야 함
      - 모델 적합에 사용된 자료를 평가를 위해 재활용하지 않고, 평가만을 위한 데이터를 확보할 필요가 있음

  - 모델 검증 및 평가를 위한 데이터의 구분 

    - Hold-out방식

      - 주어진 자료를 다음의 세 그룹으로 랜덤하게 분할한 뒤, 주어진 목적에 따라 각각 훈련, 검증, 평가에 활용함

      1. 훈련 데이터(training data) - 모델 학습을 위해 사용되는 자료
      2. 검증 데이터(validation data) - 훈련 자료로 적합되는 모델을 최적의 성능으로 튜닝하기 위해 사용되는 자료. 훈련에 필요한 하이퍼 파라미터를 조정하거나 변수선택 등에 이용
      3. 평가 데이터(test data) - 훈련 및 검증 자료로 적합된 최종 모형이 미래에 주어질 새로운 자료에 대하여 얼마나 좋은 성과를 갖는지를 평가하는데 사용되는 자료

    - K-fold 교차검증(Cross-validation) 방식

      - **자료의 수가 충분하지 않은 경우**에는 훈련 데이터에서 너무 많은 양의 데이터를 검증 또는 평가 데이터에 뺏기지 않도록 교차 검정 기법을 사용

      1. 자료를 균등하게 k개의 그룹으로 분할한 뒤
      2. 각 j에 대하여, j 번째 그룹을 제외한 나머지 k-1개 그룹의 자료를 이용하여 모델을 적합
      3. j번째 그룹의 자료에 적합된 모델을 적용한 뒤 예측오차를 구함
      4. j=1~ k에 대하여 위의 과정을 반복한 뒤, k개의 예측 오차의 평균을 구함
      5. 예측오차의 평균값을 기준으로, 모델의 검증 또는 평가를 수행

- 일반화 오차 및 편향-분산 트레이드 오프

  - 편향-분산 트레이드 오프(Bias-Variance Trade off)
    - 모델의 복잡한 정도에 따라 훈련 데이터와 평가 데이터의 예측오차는 일반적으로 모델 적합도가 높아질수록 prediction error 점차 떨어지다가 일정 구간을 지나면 상승하게 된다. model complexity가 낮으면 Bias가 높고, model complexity가 높으면 Bias가 낮다. (Bias는 정확도 개념, 편향)
    -  model complexity 낮으면 variance가 낮음 model complexity가 높으면 variance가 높아짐.
    - 즉 best complexity를 찾아야 함
  - 과대적합을 막기 위한 방법
    - 훈련 데이터를 많이 확보
    - 모델의 복잡도를 낮춤
      - 특성 변수의 수를 줄이거나 차원축소
      - 파라미터에 규제(regularization)를 적용

- 회귀(Regression)모델의 평가 지표

  - RMSE(Root mean sqaure error)
  - R-square(결정계수): 0~ 1사이의 값을 가지며 1에 가까울수록 좋다.
  - MAE(mean absolute error): 오차의 부호만 제거해서 이를 평균한 값. 오차가 평균적으로 10정도 발생한다고 이해
  - MAPE(mean average percentage error): 실제 값 대비 오차가 차지하는 비중이 평균적으로 얼마인지 확인

- 분류(Classification) 모델의 평가 지표

  - 정오분류표(confusion matrix)
    - ​                                      모형에 의한 예측(predict)	
    - ​                                              Negative           Positive
    - 실제 자료 (actual) Negative      TN, true neg      FP, false pos
    - ​                           Positive        FN, false neg      TP, true pos   
  - 정확도, 정분류율(Accuracy)
    - 전체 관찰치 중 정분류된 관찰치의 비중
    - 정밀도(precision): positive로 예측한 것 중 실제 범주도 positive인 데이터의 비율
    - 재현율(recall): 실제 positive인 것 중에서 positive로 예측된 데이터의 비율
  - ROC(receiver operating characteristic) 도표
    - 분류의 결정임계값(threshold)에 따라 달라지는 TPR(민감도, sensitivity)과 FPR(1-특이도, 1-specificity)의 조합을 도표로 나타냄
    - TPR: True Positive Rate(=sensitivity(민감도))
      - 1인 케이스에 대해 1로 잘 예측한 비율
    - FPR: False Positive Rate(=1-specificity(특이도))
    - 임계값이 1이면 FPR=0, TPR = 0
    - 임계값을 1에서 0으로 낮춰감에 따라 FPR과 TPR은 동시에 증가함
    - FRP이 증가하는 정도보다 TPR이 빠르게 증가하면 이상적
      - 그래프가 왼쪽 위 꼭지점에 가까울수록 좋음
  - AUC(Area Under the Curve)
    - ROC곡선 아래의 면적
    - 가운데 대각선의 직선은 랜덤한 수준의 이진분류에 대응되며, 이경우 AUC는 0.5임
    - 1에 가까울수록 좋은 수치. FPR이 작을 때 얼마나 큰 TPR을 얻는지에 따라 결정됨