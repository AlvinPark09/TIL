## 다중회귀분석(multiple Linear Regression)

- 다중 선형회귀모형
  - 독립변수가 두 개 이상인 선형회귀 모형
  - 여러 개의 독립변수를 이용하면 종속변수의 변화를 더 잘 설명할 수 있을 것임
  - 오차항인 e1~n 서로 독립인 확률변수로 (오차가정): 정규, 등분산, 독립
  - 회귀 계수 알파, 베타(변수들)와 분산은 미지인 모수로 상수임
    - 베타(변수들)의 해석: x를 제외한 **나머지 모든 예측 변수들을 상수로 고정**시킨 상태에서 x의 한 단위 증가에 따른 Y기대값의 증분
  - 범주형 독립변수가 포함된 회귀모형
    - 범주형 독립 변수를 회귀모형에 포함하기 위해서는 더미변수 기법을 사용
    - 더비 변수는 0또는 1의 값을 갖는 변수로 아래와 같이 정의됨
    - 다른 독립변수와 독립변수 사이에 완벽한 선형관계에 해당하는 경우가 있다면 계수를 추정할 수 없다
- 다중회귀모형의 변수선택
  - 가능한 적은 수의 설명변수로 좋은 예측력을 가지는 모형을 찾고자 함
  - 변수 선택법
    - 전진선택법
      - 절편만 있는 모델에서 출발하여 중요한 변수를 하나씩 추가하는 방식
      - **한 번 선택된 변수는 제거되지 않는 단점**이 있음
    - 후진제거법
      - 모든 변수가 포함된 모델에서 가장 중요하지 않은 변수부터 하나씩 제거.
      - **한번 제거된 변수는 서택되지 않는 단점**이 있음
    - **단계선택법(stepwise method)**
      - 절편만 포함된 모델에서 출발해 **가장 중요한 변수부터 추가**하고, 모델에 포함되어 있는 **변수 중에서 중요하지 않은 변수를 제거**함
      - 더 이상 **새롭게 추가되는 변수가 없을 때까지 변수의 추가 또는 삭제를 반복**
    - 모든 가능한 조합의 회귀분석: 모든 가능한 독립변수들의 조합에 대한 회귀모형을 생선한 뒤 가장 적합한 회귀모형을 선택
- 모형 선택의 기준
  - 수정된 결성계수 (adjusted R2) (클수록 좋음)
    - 결정계수 R2는 새로운 독립변수가 추가되면 항상 증가함.
    - 이를 보완한 수정결정계수 adjusted R2는 추가된 독립변수가 종속변수를 설명하는데 기여하는 바가 큰 경우에만 증가함
  - 그 밖에 AIC, BIC, mallow's Cp등의 다양한 적합도 지표를 이용 가능 (작을수록 좋음)
- 다중회귀모형의 가정 위반 검토 및 해결
  - 잔차분석
    - 회귀 모형에서의 가정이 적절한 것인가에 대한 평가
      - 오차의 정규성
      - 오차의 등분산성
      - 오차이 독립성
    - 오차는 확률변수로 관찰되지 않는 값이므로, 각 오차에 대응되는 잔차를 관찰한 뒤 잔차들의 분포를 통해 오차에 대한 가정의 적정성을 확인 할 수 있음.
    - 잔차 분석 방법
      - 각 가정 별로, 검정을 통한 방법과 그래프를 통한 시각적인 확인 방법이 가능
      - 시각적 방법을 이용할 경우,
        - 오차의 정규성 위반: 히스토그램, qqplot
        - 오차의 등분산성: 잔차산점도
        - 오차의 독립성: 잔차산점도
  - 가정 위반 시 해결방안
    - 오차의 정규성 위반 : 변수 변환
    - 오차의 등분산성: 가중최소제곱회귀
    - 오차의 독립성: 시계열 분석
- 다중공선성 진단 및 해결
  - 다중공선성
    - 독립변수들 간에 강한 선형관계가 존재하는 경우
    - 다중회귀모형 분석 시 자주 발생하는 문제 중 하나임
    - 다중회귀모형에서 회귀계수 추정에 부정적인 영향을 미침
      - 개별적인 회귀계수 추정의 신뢰성이 떨어져 추정치를 믿을 수 없게 많듦
      - 전반적인 모형의 적합성이나 정확도는 크게 변하지 않음
    - 다중공선성 진단 방법
      - VIF 계수 도출
        1. R2 : x 종속변수로 두고 나머지 독립변수로 설명하는 다중선형회귀모델에서의 결정계수
      - VIF계수가 5또는 10이상인 경우 다중 공선성이 심각한 것으로 봄
    - 다중공선성 해결책
      - 변수선택으로 중복된 변수를 제거
      - 주성분 분석(PCA) 등을 이용하여 중복된 변수를 변환하여 새로운 변수 생성
      - 릿지, 라쏘 등으로 중복된 변수의 영향력을 일부만 사용
- 규제가 있는 선형회귀모델(Ridge, Lasso, Elastic Net)
  - 선형회귀모델의 규제
    - 모형의 과대적합을 막기 위한 규제 방법(regularization)으로 선형회귀모형에서는 보통 모델의 가중치를 제한하는 방법을 사용
    - 가중치를 제한하는 방법에 따른 규제 선형회귀모델의 종류
      - 릿지회귀(ridge regression) (와 L2 규제)
        - 비용함수에 규제항이 추가된 선형회귀모형
        - 람다(규제정도를 결정하는 하이퍼파라미터)
          - 람다가 크면 규제 많음. 회귀계수 추정치가 작아짐
          - 람다가 0이면 일반 선형회귀모델과 동일한 결과
          - 적절한 람다는 교차검증 등으로 최적화
        - Alternative Formulation
          - 어떤 임의의 람다에 대해 이에 대응하는 하나의 t가 존재하여, 일정 식으로 동일한 해 b(베타)를 얻게 됨.
      - 라쏘회귀(lasso regression) (와 L1 규제)
        - 비용함수에 규제항이 추가된 선형회귀 모형
        - 람다(규제정도를 결정하는 하이퍼파라미터), 교차검증 등으로 최적화
        - Alternative Formulation
          - 어떤 임의의 람다에 대해 이에 대응하는 하나의 t가 존재하여, 일정 식으로 동일한 해 b(베타)를 얻게 됨.
      - 릿지회귀와 라쏘회귀의 특징
        - 두 방식 모두 추정치는 일반선형회귀모형과는 달리 편의가 발생하지만, 분산은 더 작아지게 됨 -> 람다에 따라 일반화 오차가 더 작아질 수 있음
        - 라쏘 회귀의 경우 제약 범위가 각진 형대 -> 파라미터의 일부가 0이 되는 경향이 있음(sparse model)
        - 릿지 회귀의 경우 제약 범위가 원의 형태 -> 파라미터가 0이 되지 않고 전반적으로 줄어드는 경향이 있음
      - 엘라스틱넷(Elastic Net)
        - L1과 L2규제를 혼합한 방식
        - 릿지회귀와 라쏘회귀의 장점을 모두 가짐
